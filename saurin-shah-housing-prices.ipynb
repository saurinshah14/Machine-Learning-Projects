{"cells":[{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"## EXPLORATORY DATA ANALYSIS","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"# Importing necessary libraries","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"scrolled":false},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"pd.pandas.set_option('display.max_columns', None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"dataset = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv')\nprint(dataset.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"# Finding the % of missing values (NA or NULL) in each column, upto 4 decimal places","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"features_with_na = [features for features in dataset.columns if dataset[features].isnull().sum()>1]\n\nfor feature in features_with_na:\n    print(feature, np.round(dataset[feature].isnull().mean(),4), \"% missing values\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"# For each feature, bar plot (feature vs SalePrice) where NULL values are at 1 and the remaining are at 0\n# This will help to see in which feature there are more NULL values as compared to non-NULL values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"for feature in features_with_na:\n    data = dataset.copy()\n    \n    data[feature] = np.where(data[feature].isnull(),1,0)\n    \n    data.groupby(feature)['SalePrice'].median().plot.bar()\n    plt.title(feature)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"print(\"ID of houses: {} \" . format(len(dataset.Id)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"# Finding total number of numerical features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"numerical_features = [feature for feature in dataset.columns if dataset[feature].dtypes != 'object']\n\nprint(\"No of numerical variables: \", len(numerical_features))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"dataset[numerical_features].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"# In numerical features, finding year features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"year_feature = [feature for feature in numerical_features if \"Yr\" in feature or \"Year\" in feature]\nyear_feature","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"for feature in year_feature:\n    print(feature, dataset[feature].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"# Graph of year sold vs median house price. This shows the plot of the median house price for each year in the year sold feature","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"dataset.groupby(\"YrSold\")[\"SalePrice\"].median().plot()\nplt.xlabel(\"Year Sold\")\nplt.ylabel(\"Median House Price\")\nplt.title(\"House Price vs Year Sold\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"# We observe that with increasing year sold, the sale price decreases\n# Scatter plot to see relationship between other year features and year sold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"for feature in year_feature:\n    if feature != \"YrSold\":\n        data = dataset.copy()\n        data[feature] = data[\"YrSold\"] - data[feature]\n        \n    plt.scatter(data[feature], data[\"SalePrice\"])\n    plt.xlabel(feature)\n    plt.ylabel(\"SalePrice\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"# Calculating number of discrete features from the numerical features, excluding the ID and year feature","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"discrete_feature = [feature for feature in numerical_features if len(dataset[feature].unique())<25 and feature not in year_feature + [\"Id\"]]\nprint(\"Discrete Variables Count: {} \".format(len(discrete_feature)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"discrete_feature","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"dataset[discrete_feature].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Relationship between discrete features and dependent feature Sale Price","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"for feature in discrete_feature:\n    data = dataset.copy()\n    data.groupby(feature)[\"SalePrice\"].median().plot.bar()\n    plt.xlabel(feature)\n    plt.ylabel(\"SalePrice\")\n    plt.title(feature)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculating number of continuous features from the numerical features, excluding the ID and year feature","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"continuous_feature = [feature for feature in numerical_features if feature not in discrete_feature + year_feature + [\"Id\"]]\ncontinuous_feature","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"print(\"Continuous Feature Count: {}\". format(len(continuous_feature)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Histogram plot of each continuous feature","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"for feature in continuous_feature:\n    data = dataset.copy()\n    data[feature].hist(bins=25)\n    plt.xlabel(feature)\n    plt.ylabel(\"Count\")\n    plt.title(feature)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Log Normalization of only those features in which no value at 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"for feature in continuous_feature:\n    data = dataset.copy()\n    if 0 in data[feature].unique():\n        pass\n    else:\n        data[feature] = np.log(data[feature])\n        data[\"SalePrice\"] = np.log(data[\"SalePrice\"])\n        plt.scatter(data[feature],data[\"SalePrice\"])\n        plt.xlabel(feature)\n        plt.ylabel(\"SalePrice\")\n        plt.title(feature)\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"# Outliers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in continuous_feature:\n    data = dataset.copy()\n    if 0 in data[feature].unique():\n        pass\n    else:\n        data[feature] = np.log(data[feature])\n        data.boxplot(column=feature)\n        plt.ylabel(feature)\n        plt.title(feature)\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Categorical Features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_features = [feature for feature in dataset.columns if data[feature].dtypes == \"object\"]\ncategorical_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(categorical_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset[categorical_features].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in categorical_features:\n    print(\"The feature is {} and the number of categories are {}\". format(feature, len(dataset[feature].unique())))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Relationship between categorical features and dependent feature Sale Price","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in categorical_features:\n    data = dataset.copy()\n    data.groupby(feature)[\"SalePrice\"].median().plot.bar()\n    plt.xlabel(feature)\n    plt.ylabel(\"SalePrice\")\n    plt.title(feature)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## FEATURE ENGINEERING","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# FEATURE ENGINEERING FOR TRAIN DATA","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# To prevent data leakage, train-test split needs to be done. In our case we already have the data split into training and testing data\n# code for train-test split\n# from sklearn.model_selection import train_test_split\n# X_train, X_test, y_train, y_test = train_test_split(dataset,dataset[\"SalePrice\"],test_size=0.1,random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Missing Values\n\n# Missing Categorical Values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_nan = [feature for feature in dataset.columns if dataset[feature].isnull().sum()>1 and dataset[feature].dtypes == \"object\"]\n\nfor feature in features_nan:\n    print(\"{}: {}% missing values\".format(feature,np.round(dataset[feature].isnull().mean(),4)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replacing NAN values with new labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def replace_cat_features(dataset,features_nan):\n    data = dataset.copy()\n    data[features_nan]=data[features_nan].fillna(\"Missing\")\n    return data\n\ndataset = replace_cat_features(dataset,features_nan)\ndataset[features_nan].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Missing Numerical Values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_with_nan = [feature for feature in dataset.columns if dataset[feature].isnull().sum()>1 and dataset[feature].dtypes != \"object\"]\n\nfor feature in numerical_with_nan:\n    print(\"{}: {}% missing values\".format(feature,np.round(dataset[feature].isnull().mean(),4)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replacing NULL numerical values. As outliers exist, replacing NAN values with median","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in numerical_with_nan:\n    median_value=dataset[feature].median()\n    \n    dataset[feature+\"nan\"]=np.where(dataset[feature].isnull(),1,0)\n    dataset[feature].fillna(median_value,inplace=True)\n    \ndataset[numerical_with_nan].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head(50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Temporal Variables (Date-time variables)\n# Instead of the year value, we try to find number of years, by finding difference between the year sold and the year of the feature\n\nfor feature in [\"YearBuilt\",\"YearRemodAdd\",\"GarageYrBlt\"]:\n    \n    dataset[feature] = dataset[\"YrSold\"]-dataset[feature]\n    \ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset[[\"YearBuilt\",\"YearRemodAdd\",\"GarageYrBlt\"]].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Numerical Variables are skewed, thus we perform log normal distribution","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nnum_features = [\"LotFrontage\", \"LotArea\", \"1stFlrSF\", \"GrLivArea\", \"SalePrice\"]\n\nfor feature in num_features:\n    dataset[feature]=np.log(dataset[feature])\n    \ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Handling Rare Categorical Features\n# They are those features in which a category in the feature is less than 1% of total observations. ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_features = [feature for feature in dataset.columns if dataset[feature].dtype==\"object\"]\ncategorical_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in categorical_features:\n    temp=dataset.groupby(feature)[\"SalePrice\"].count()/len(dataset)\n    temp_df=temp[temp>0.01].index\n    dataset[feature]=np.where(dataset[feature].isin(temp_df),dataset[feature],\"Rare_var\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head(100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in categorical_features:\n    labels_ordered=dataset.groupby(feature)[\"SalePrice\"].mean().sort_values().index\n    labels_ordered={k:i for i,k in enumerate (labels_ordered,0)}\n    dataset[feature]=dataset[feature].map(labels_ordered)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## FEATURE SCALING FOR TRAIN DATA","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_scale = [feature for feature in dataset.columns if feature not in [\"Id\", \"SalePrice\"]]\n\nfrom sklearn.preprocessing import MinMaxScaler\nscaler=MinMaxScaler()\nscaler.fit(dataset[feature_scale])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler.transform(dataset[feature_scale])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# transform the train and test set, and add on the Id and SalePrice variables\ntrain_data = pd.concat([dataset[['Id', 'SalePrice']].reset_index(drop=True),\n                    pd.DataFrame(scaler.transform(dataset[feature_scale]), columns=feature_scale)],\n                    axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_data.to_csv('X_train.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# FEATURE ENGINEERING FOR TEST DATA","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\npd.pandas.set_option('display.max_columns', None)\n\ndataset = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/test.csv')\nprint(dataset.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_nan = [feature for feature in dataset.columns if dataset[feature].isnull().sum()>1 and dataset[feature].dtypes == \"object\"]\n\nfor feature in features_nan:\n    print(\"{}: {}% missing values\".format(feature,np.round(dataset[feature].isnull().mean(),4)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def replace_cat_features(dataset,features_nan):\n    data = dataset.copy()\n    data[features_nan]=data[features_nan].fillna(\"Missing\")\n    return data\n\ndataset = replace_cat_features(dataset,features_nan)\ndataset[features_nan].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_with_nan = [feature for feature in dataset.columns if dataset[feature].isnull().sum()>1 and dataset[feature].dtypes != \"object\"]\n\nfor feature in numerical_with_nan:\n    print(\"{}: {}% missing values\".format(feature,np.round(dataset[feature].isnull().mean(),4)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in numerical_with_nan:\n    median_value=dataset[feature].median()\n    \n    dataset[feature+\"nan\"]=np.where(dataset[feature].isnull(),1,0)\n    dataset[feature].fillna(median_value,inplace=True)\n    \ndataset[numerical_with_nan].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in [\"YearBuilt\",\"YearRemodAdd\",\"GarageYrBlt\"]:\n    \n    dataset[feature] = dataset[\"YrSold\"]-dataset[feature]\n    \ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nnum_features = [\"LotFrontage\", \"LotArea\", \"1stFlrSF\", \"GrLivArea\"]\n\nfor feature in num_features:\n    dataset[feature]=np.log(dataset[feature])\n    \ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_features = [feature for feature in dataset.columns if dataset[feature].dtype==\"object\"]\ncategorical_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in categorical_features:\n    temp=dataset.groupby(feature)[\"Id\"].count()/len(dataset)\n    temp_df=temp[temp>0.01].index\n    dataset[feature]=np.where(dataset[feature].isin(temp_df),dataset[feature],\"Rare_var\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in categorical_features:\n    labels_ordered=dataset.groupby(feature)[\"Id\"].mean().sort_values().index\n    labels_ordered={k:i for i,k in enumerate (labels_ordered,0)}\n    dataset[feature]=dataset[feature].map(labels_ordered)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# FEATURE SCALING FOR TEST DATA","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_scale = [feature for feature in dataset.columns if feature not in [\"Id\"]]\n\nfrom sklearn.preprocessing import MinMaxScaler\nscaler=MinMaxScaler()\nscaler.fit(dataset[feature_scale])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler.transform(dataset[feature_scale])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# transform the train and test set, and add on the Id and SalePrice variables\ntest_data = pd.concat([dataset[['Id']].reset_index(drop=True),\n                    pd.DataFrame(scaler.transform(dataset[feature_scale]), columns=feature_scale)],\n                    axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_data.to_csv('X_test.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## FEATURE SELECTION","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n## for feature slection\n\nfrom sklearn.linear_model import Lasso\nfrom sklearn.feature_selection import SelectFromModel\n\n# to visualise al the columns in the dataframe\npd.pandas.set_option('display.max_columns', None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset=train_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Capture the dependent feature\ny_train=dataset[['SalePrice']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## drop dependent feature from dataset\nX_train=dataset.drop(['Id','SalePrice'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Apply Feature Selection\n# first, I specify the Lasso Regression model, and I\n# select a suitable alpha (equivalent of penalty).\n# The bigger the alpha the less features that will be selected.\n\n# Then I use the selectFromModel object from sklearn, which\n# will select the features which coefficients are non-zero\n\nfeature_sel_model = SelectFromModel(Lasso(alpha=0.005, random_state=0)) # remember to set the seed, the random state in this function\nfeature_sel_model.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_sel_model.get_support()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's print the number of total and selected features\n\n# this is how we can make a list of the selected features\nselected_feat = X_train.columns[(feature_sel_model.get_support())]\n\n# let's print some stats\nprint('total features: {}'.format((X_train.shape[1])))\nprint('selected features: {}'.format(len(selected_feat)))\nprint('features with coefficients shrank to zero: {}'.format(\n    np.sum(feature_sel_model.estimator_.coef_ == 0)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"selected_feat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train=X_train[selected_feat]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost\nclassifier=xgboost.XGBRegressor()\nclassifier.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test=test_data[selected_feat]\nX_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_train=classifier.predict(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_test=classifier.predict(X_test)\ny_pred_test","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}